<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on /dev/null</title>
    <link>http://rlouf.github.com/post/</link>
    <description>Recent content in Posts on /dev/null</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Jan 2019 13:19:11 +0100</lastBuildDate>
    
	<atom:link href="http://rlouf.github.com/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Massively parallel MCMC with JAX</title>
      <link>http://rlouf.github.com/post/jax-random-walk-metropolis/</link>
      <pubDate>Wed, 09 Jan 2019 13:19:11 +0100</pubDate>
      
      <guid>http://rlouf.github.com/post/jax-random-walk-metropolis/</guid>
      <description>Disclaimers:
 Yeah that&#39;s probably not the proper way to do benchmark; That&#39;s probably not a fair benchmark, I&#39;m interested in your suggestions to make it more fair. In particular, tensorflow-probability is not shining here so I must be doing something wrong.  This post was inspired by Colin Caroll&#39;s blog post on running a vectorized version of MCMC to get multiple chains at once.
So far, running multiple chains at once was reserved to performing posterior checks on the convergence of algorithms, or reducing the variance (not the biais) of the results of Monte Carlo sampling.</description>
    </item>
    
  </channel>
</rss>