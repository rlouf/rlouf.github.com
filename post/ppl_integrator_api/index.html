<!DOCTYPE html>
<html lang="en-us">

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Hugo 0.78.2" />

  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="">
  <meta property="og:url" content="http://rlouf.github.com/post/ppl_integrator_api/">

  <title>Designing modular inference engines: API for the HMC kernel - /dev/null</title>
  <meta property="og:title" content="Designing modular inference engines: API for the HMC kernel - /dev/null">
  <meta property="og:type" content="article">
  <meta name="description" content="">

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Source+Serif+Pro:400,700">
  <link rel="stylesheet" href="/css/highlight.css">
  <link rel="stylesheet" href="/css/journal.css">
  <link href="/index.xml" rel="alternate" type="application/rss+xml" title="/dev/null">

</head>

<body>
  <div class="container">

    <nav class="site-nav">
      <a href="http://rlouf.github.com/">Index</a>
    </nav>


  <article class="post">
    <header class="post-header">
      <h1 class="post-title">Designing modular inference engines: API for the HMC kernel</h1>
      <time class="post-date" datetime="2020-02-13 09:13:38 CET">13 Feb 2020</time>
    </header>

    <p>I have been working on a probabilistic programming library,
<a href="https://github.com/rlouf/mcx">MCX</a> (don&rsquo;t use it yet, most of the inference
engine is in API prototype stage) for the past few weeks. The library is based
on source code transformation: you express the model as a python function, and a
compiler reads the function, applies the necessary transformations and outputs
either a function that generates samples from this distribution, or its logpdf.
The logpdf can be JIT-compiled with JAX and used for batched inference.</p>
<p>Despite the black magic involved, this scheme is convenient; it neatly separates
the process of defining the model and that of performing inference, with python
functions as the bridge between the two. Algorithm-specific optimizations are
done at compilation time; as a result, inference algorithms need not be aware of
how the logpdf was generated and can execute it &ldquo;as is&rdquo;.</p>
<p>It is even possible to use inference engines without using MCX&rsquo;s DSL: users can
import the <code>inference</code> module in their projects and use custom-built functions
as logpdfs. As long at the logpdf is compatible with JAX&rsquo;s <code>jit</code> and <code>grad</code> the
inference with work out of the box. <em>Designed appropriately, MCX could be used
both for its DSL and convenient interface with common algorithms, but also for
the composability of its inference elements.</em></p>
<p>Since we wish to expose the internals to experienced users there is a strong
incentive to make the inference engine as modular as is possible and its parts
re-usable. This way, users can come up with combinations that are not yet
implemented in MCX or even build their own parts.</p>
<h2 id="hamiltonian-monte-carlo">Hamiltonian Monte Carlo</h2>
<p>Hamiltonian Monte Carlo (HMC) methods are the cornerstone of most PPLs:
<a href="https://probprog.github.io/anglican/">Anglican</a>,
<a href="http://pyro.ai/numpyro/">Numpyro</a>, <a href="https://docs.pymc.io/">PyMC3</a>,
<a href="https://pyro.ai/">Pyro</a>, <a href="https://mc-stan.org/">Stan</a>, <a href="https://www.tensorflow.org/probability">Tensorflow
Probability</a>,
<a href="https://turing.ml/dev/">Turing.jl</a>, <a href="https://rainier.fit/">Rainier</a>,
<a href="https://github.com/cscherrer/Soss.jl">Soss.jl</a>, and many others I forgot
(someone should write about the current Cambrian explosion of PPLs!) are all
built around variants of Hamiltonian Monte Carlo. If you don&rsquo;t already know why
everyone is using HMC, have a look at <a href="https://arxiv.org/abs/1410.5110">Betancourt&rsquo;s article</a> for a theoretical explanation.</p>
<p>When it comes to implementation, here is the implementation of HMC that you
often find (I omitted the implementation of the integrator for simplicity):</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">HMCState</span>(NamedTuple):
    <span style="color:#e6db74">&#34;&#34;&#34;State on which the HMC kernel acts.
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    We can (and probably should) add more information which can be useful
</span><span style="color:#e6db74">    higher up:
</span><span style="color:#e6db74">      - State of the proposal
</span><span style="color:#e6db74">      - Whether the move was accepted
</span><span style="color:#e6db74">      - Acceptance ratio
</span><span style="color:#e6db74">      - State of the integrator
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    position: Array
    log_prob:float
    log_prob_grad: float
    energy: float  <span style="color:#75715e"># here for convenience</span>


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">hmc_kernel</span>(
    potential: Callable,
    integrator: Callable,  <span style="color:#75715e"># integrates the trajectory</span>
    momentum_generator: Callable,  <span style="color:#75715e"># generates a momentum value</span>
    kinetic_energy: Callable,  <span style="color:#75715e"># computes kinetic energy from momentum value</span>
    num_integration_steps: int,
    step_size: float,
):
    
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">step</span>(rng_key, state: HMCState) <span style="color:#f92672">-&gt;</span> HMCState:
        <span style="color:#e6db74">&#34;&#34;&#34;Moves the chain by one step using the Hamiltonian dynamics.
</span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
        key_momentum, key_uniform <span style="color:#f92672">=</span> jax<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>split(rng_key)

        momentum <span style="color:#f92672">=</span> momentum_generator(key_momentum)
        position, momentum, log_prob, log_prob_grad <span style="color:#f92672">=</span> integrator(
            potential,
            state<span style="color:#f92672">.</span>position,
            momentum,
            state<span style="color:#f92672">.</span>log_prob_grad,
            num_integration_steps,
            step_size,
        )
        new_energy <span style="color:#f92672">=</span> log_prob <span style="color:#f92672">+</span> kinetic_energy(momentum)
        new_state <span style="color:#f92672">=</span> HMCState(position, log_prob, log_prob_grad, new_energy)

        log_uniform <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>log(jax<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(rng_key))
        do_accept <span style="color:#f92672">=</span> log_uniform <span style="color:#f92672">&lt;</span> new_energy <span style="color:#f92672">-</span> state<span style="color:#f92672">.</span>energy
        <span style="color:#66d9ef">if</span> do_accept:
            <span style="color:#66d9ef">return</span> new_state

        <span style="color:#66d9ef">return</span> state

    <span style="color:#66d9ef">return</span> step
</code></pre></div><p>where <code>integrator</code> can be the often-used leapfrog integrator, or any other
symplectic integrator. Separating <code>momentum_generator</code>, <code>kinetic_energy</code> and
<code>integrator</code> allows you to easily generalize to Riemannian HMC, without having
to re-define a kernel for every possibe combination.</p>
<p>But this implementation has its limits, which often cause PPLs to copy-paste a
good portion of the code whenever a new member of the HMC family is introduced.
In particular empirical HMC (eHMC) and NUTS where the number of integration steps
changes between iterations. It is temptin to pass <code>step_size_generator</code> and
<code>path_length_generator</code> to <code>hmc</code>. While this works for eHMC and algorithms with
an adaptive step size, it fails to accomodate more complex schemes like NUTS.</p>
<p>With hindsight, what I am about to write feels like stating the obvious: this
design smells because it is conceptually incorrect; <em>the step size and path
length are not properties of the kernel, but of the path integration.</em> We can
even go further, and separate proposals from integration. After all, both eHMC
and NUTS do call the same integrators and there is no reason they should be
&ldquo;trapped&rdquo; in a specific proposal.</p>
<p>For empirical HMC where the path length is drawn from an empirical distribution
with <code>num_steps_generator</code>, this would look like:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">ehmc_proposal</span>(
    step_size: float,
    num_steps_generator: Callable,  <span style="color:#75715e"># returns a number of steps</span>
    integrator: Callable <span style="color:#f92672">=</span> leapfrog,
):

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">propose</span>(rng_key, state):
        num_integration_steps <span style="color:#f92672">=</span> num_steps_generator(rng_key)
        <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(num_integration_steps): 
            state <span style="color:#f92672">=</span> integrator(state, step_size)
        <span style="color:#66d9ef">return</span> state
      
    <span style="color:#66d9ef">return</span> propose
</code></pre></div><p>Note that by using a closure we can make every proposal depend only on a PRNG key
and the chain state. In other words, they are kernels and all provide the same
interface to the kernel. This way we can accomodate virtually any variation on
HMC while using the same kernel. The HMC kernel now looks like:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">hmc_kernel</span>(
    logpdf: Callable,
    proposal: Callable,
    momentum_generator: Callable,
    kinetic_energy: Callable,
):
    
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">step</span>(rng_key, state: HMCState) <span style="color:#f92672">-&gt;</span> HMCState:
        <span style="color:#e6db74">&#34;&#34;&#34;Moves the chain by one step using the Hamiltonian dynamics.
</span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
        key_momentum, key_uniform <span style="color:#f92672">=</span> jax<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>split(rng_key)

        momentum <span style="color:#f92672">=</span> momentum_generator(key_momentum)
        position, momentum, log_prob, log_prob_grad <span style="color:#f92672">=</span> proposal(
            logpdf,
            state<span style="color:#f92672">.</span>position,
            momentum,
            state<span style="color:#f92672">.</span>log_prob,
            state<span style="color:#f92672">.</span>log_prob_grad,
        )
        new_energy <span style="color:#f92672">=</span> log_prob <span style="color:#f92672">+</span> kinetic_energy(new_momentum)
        new_state <span style="color:#f92672">=</span> HMCState(position, log_prob, log_prob_grad, new_energy)

        log_uniform <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>log(jax<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(rng_key))
        do_accept <span style="color:#f92672">=</span> log_uniform <span style="color:#f92672">&lt;</span> new_energy <span style="color:#f92672">-</span> state<span style="color:#f92672">.</span>energy
        <span style="color:#66d9ef">if</span> do_accept:
            <span style="color:#66d9ef">return</span> new_state

        <span style="color:#66d9ef">return</span> state

    <span style="color:#66d9ef">return</span> step
</code></pre></div><p>And here is a summary of the decomposition of the algorithms into independent
parts:</p>
<pre><code>
          +--&gt; Momentum generator      
          |         |              step size (generator)
          |         v                    v
Metric ---+      Kernel &lt;----------- Proposal  &lt;---------- Integrator
          |         ^                    ^
          |         |               num steps (generator)
          +--&gt; Kinetic Energy             


</code></pre><p>Decomposing the HMC kernel in meaningful blocks and specializing using a closure
brings a lot of benefits:</p>
<ul>
<li>The logic of the kernel is more transparent;</li>
<li>The code is more modular; we can separate the implementations of the dynamics
(momentum and kinetic energy) and trajectory integration. We are free to use
any symplectic integrator (2nd, 3rd, etc. order)<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, use any metric (euclidean,
riemannian, etc.) and any variant in implementation.</li>
<li>One can initialize a kernel with algorithms that are not in the library. These
algorithm only need to expose the same API as the others.</li>
</ul>
<p>A couple of examples:</p>
<ul>
<li>Vanilla HMC uses a Euclidean metric, a fixed step size and a fixed number of
steps. We can use any integrator we want.</li>
<li>empirical HMC uses a distribution for the number of integration steps, a fixed
step size.</li>
<li>NUTS uses a fixed step size, but a complex internal logic to determine the
number of integration steps.</li>
<li>For all the above you can switch the metric to a Riemannian metric and use the
appropriate integrator.</li>
</ul>
<p>This makes development easier and less error-prone.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I am particularly excited about being able to implement and use
algorithms mentioned in <a href="https://arxiv.org/abs/1711.05337">this review paper</a>. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>


  </article>


      <footer class="site-footer">
        <span itemscope itemtype="http://schema.org/Person">
          <link itemprop="url" href="http://rlouf.github.com/">
          <span itemprop="name"></span>

          <br>

          <a itemprop="sameAs" href="https://github.com/rlouf" title="GitHub">Github</a>

          <a itemprop="sameAs" href="https://twitter.com/remilouf" title="Twitter">Twitter</a>

          
        </span>

        
      </footer>
    </div>

  <script src="/js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

	<script type="text/javascript"
	src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			tex2jax: {
				 inlineMath: [['$','$'], ['\\(','\\)']],
				 displayMath: [['$$','$$']],
				 processEscapes: true,
				 processEnvironments: true,
				 skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
				 TeX: { equationNumbers: { autoNumber: "AMS" },
								extensions: ["AMSmath.js", "AMSsymbols.js"] }
			}
		});
	</script>

  </body>
</html>

